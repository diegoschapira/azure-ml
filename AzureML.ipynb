{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.68\n"
     ]
    }
   ],
   "source": [
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize existing workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: C:\\Users\\schapira.d\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "subscription_id = \"xxxxxxxxx\"\n",
    "resource_group = \"xxxxxxx\"\n",
    "workspace_name = \"xxxxxx\"\n",
    "workspace_region = \"xxxxxxx\"\n",
    "\n",
    "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "experiment_name = 'train-in-notebook'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schapira.d\\AppData\\Local\\Continuum\\Anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\schapira.d\\AppData\\Local\\Continuum\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.45      0.53        56\n",
      "          2       0.58      0.23      0.33        48\n",
      "          4       0.59      0.33      0.42        97\n",
      "          5       0.73      0.96      0.83       291\n",
      "\n",
      "avg / total       0.68      0.71      0.67       492\n",
      "\n",
      "Models saved to pickle\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn models\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "\n",
    "#Load data from local folder\n",
    "path = 'C:\\\\Users\\\\schapira.d\\\\Desktop\\\\GCR Analytics\\\\AE Classifier\\\\amazon_book_reviews.csv'\n",
    "df = pd.read_csv(path,encoding='UTF-8')\n",
    "df = df[['Rating','Text']]\n",
    "\n",
    "#Prepare data\n",
    "X = df['Text'].fillna('').tolist()\n",
    "X = [str(i) for i in X]\n",
    "y = df['Rating'].fillna('').tolist()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#Split train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=RANDOM_STATE)\n",
    "\n",
    "#Initialize models\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),stop_words='english')\n",
    "clf = LinearSVC(random_state=RANDOM_STATE)\n",
    "\n",
    "#Fit \n",
    "clf.fit(tfidf.fit_transform(X_train),y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = clf.predict(tfidf.transform(X_test))\n",
    "\n",
    "#Measure model accuracy\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy_score = accuracy_score(y_test,y_pred)\n",
    "print(report)\n",
    "#run.log('accuract score',accuracy_score)\n",
    "\n",
    "#Serialize models\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(value=tfidf, filename='tfidf_books.pkl')\n",
    "joblib.dump(value=clf, filename='LinearSVC_books.pkl')\n",
    "\n",
    "#run.upload_file(name='outputs/tfidf_books.pkl', path_or_stream='./tfidf_books.pkl')\n",
    "#run.upload_file(name='outputs/LinearSVC_books.pkl', path_or_stream='./LinearSVC_books.pkl')\n",
    "\n",
    "#run.complete()\n",
    "print(\"Models saved to pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>train-in-notebook</td><td>d6f06d1a-4670-48fc-8052-9e23713bc318</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/6939ec6c-6633-41b1-bbd0-399e20260db0/resourceGroups/AZ-RG-GCR-ML-01/providers/Microsoft.MachineLearningServices/workspaces/diegotest/experiments/train-in-notebook/runs/d6f06d1a-4670-48fc-8052-9e23713bc318\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: train-in-notebook,\n",
       "Id: d6f06d1a-4670-48fc-8052-9e23713bc318,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model tfidf_books.pkl\n",
      "Registering model LinearSVC_books.pkl\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_1 = Model.register(model_path = \"tfidf_books.pkl\",\n",
    "                       model_name = \"tfidf_books.pkl\",\n",
    "                       workspace = ws)\n",
    "\n",
    "model_2 = Model.register(model_path = \"LinearSVC_books.pkl\",\n",
    "                       model_name = \"LinearSVC_books.pkl\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model_1,model_2\n",
    "    # get model path\n",
    "    model_path1 = Model.get_model_path(model_name=\"tfidf_books.pkl\")\n",
    "    model_path2 = Model.get_model_path(model_name=\"LinearSVC_books.pkl\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model_1,model_2 = joblib.load(model_path1), joblib.load(model_path2)\n",
    "\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    # make prediction\n",
    "    data = json.loads(raw_data)['data']\n",
    "    y_pred = model_2.predict(model_1.transform(data)).tolist()\n",
    "    return json.dumps({\"prediction\": y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image my-aci-svc-2:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running........................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 6min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "#Create environment\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "with open(\"envtest.yml\",\"w\") as f: #define here file name for the environment\n",
    "    f.write(myenv.serialize_to_string())\n",
    "\n",
    "#Create ACI configuration file\n",
    "#Specify number of CPUs and gigabyte of RAM needed for your ACI container\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               description='Predict book rating from review')\n",
    "\n",
    "#Create container image\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                    runtime=\"python\", \n",
    "                                    conda_file=\"envtest.yml\")\n",
    "\n",
    "#Create Web Service from model\n",
    "service_name = 'my-aci-svc-2'\n",
    "service = Webservice.deploy_from_model(name=service_name,\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model_1,model_2],\n",
    "                                       image_config=image_config,\n",
    "                                       workspace=ws)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web service HTTP endpoint\n",
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web service HTTP endpoint:  http://13.73.178.223:80/score\n"
     ]
    }
   ],
   "source": [
    "print('Web service HTTP endpoint: ',service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [\"best book\", \"worst book\", \"i would recommend this book\"]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "text = ['best book','worst book','i would recommend this book']\n",
    "\n",
    "input_data = json.dumps({'data':text})\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prediction\": [5, 1, 5]}\n",
      "Wall time: 223 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = service.run(input_data=input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
